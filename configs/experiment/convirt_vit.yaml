# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /model: convirt_transformer_model

task_name: "convirt_vit"
train: True
test: False
seed: 42

logger:
  wandb:
    project: "pretraining"
    entity: "adlm-vision-language"
    name: "convirt_vit"
    tags:
      - "pretraining"
      - "mimic_cxr"
      - "default"
      - "no_flip"
      - "gaussian_blur"
      - "vit"
      # - "test"
      - "convirt"
    notes: "Convirt pretraining with ViT and no flip"

trainer:
  val_check_interval: .34 # connected to batch size
  gradient_clip_val: 20.0

datamodule:
  batch_size: 256
  transform_list:
    # Adapted augmentation
    # Order is important!
    - _target_: torchvision.transforms.ToTensor # Convert PIL Image to tensor
    - _target_: torchvision.transforms.RandomResizedCrop
      size: 224
      ratio: [0.8, 1.0]
    - _target_: torchvision.transforms.RandomAffine
      degrees: [-15, 15]
      translate: [0.1, 0.1]
      scale: [0.95, 1.05]
    # There is a bug in torchvision when initializing ColorJitter with hydra. See https://github.com/pytorch/vision/issues/5646
    # we have to add it manually in mimiccxr_datamodule.py
    - _target_: torchvision.transforms.ColorJitter
      contrast: [0.8, 1.2]
      brightness: [0.8, 1.2]  
    - _target_: torchvision.transforms.GaussianBlur
      kernel_size: 3
      sigma: [0.1, 2.0]
    # - _target_: torchvision.transforms.RandomHorizontalFlip
    #   p: 0.5      
    - _target_: torchvision.transforms.Resize
      size: [224, 224]
    - _target_: torchvision.transforms.Normalize
      mean: [0.398, 0.398, 0.398]
      std: [0.327, 0.327, 0.327]