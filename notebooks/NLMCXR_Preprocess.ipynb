{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "## Imports\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from PIL import UnidentifiedImageError\n",
    "import stanza\n",
    "\n",
    "pandarallel.initialize(progress_bar=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = '/vol/aimspace/projects/practical_WS2425/vision_language'\n",
    "\n",
    "NLMCXR_DIR = os.path.join(PROJECT_DIR, 'data/nlmcxr')\n",
    "NLMCXR_PNG_DIR = os.path.join(NLMCXR_DIR, 'images')\n",
    "NLMCXR_REPORTS_DIR = os.path.join(NLMCXR_DIR, 'texts/ecgen-radiology')\n",
    "\n",
    "STANZA_DIR = os.path.join(PROJECT_DIR, 'stanza_resources')\n",
    "\n",
    "# Verify paths exist\n",
    "print(f\"NLMCXR directory exists: {os.path.exists(NLMCXR_DIR)}\")\n",
    "print(f\"NLMCXR PNG directory exists: {os.path.exists(NLMCXR_PNG_DIR)}\")\n",
    "print(f\"NLMCXR REPORTS directory exists: {os.path.exists(NLMCXR_REPORTS_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths():\n",
    "    \"\"\"Get all PNG image paths from the NLMCXR dataset\"\"\"\n",
    "    image_paths = glob.glob(f'{NLMCXR_DIR}/**/*.png', recursive=True)\n",
    "    return sorted(image_paths)\n",
    "\n",
    "image_paths = get_image_paths()\n",
    "print(f\"Found {len(image_paths)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report_paths():\n",
    "    \"\"\"Get all report paths from the NLMCXR dataset\"\"\"\n",
    "    report_paths = glob.glob(f'{NLMCXR_REPORTS_DIR}/**/*.xml', recursive=True)\n",
    "    return sorted(report_paths)\n",
    "\n",
    "report_paths = get_report_paths()\n",
    "print(f\"Found {len(report_paths)} reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_xml_files():\n",
    "    \"\"\"\n",
    "    Parse XML files and extract relevant information into a DataFrame\n",
    "    \n",
    "    Args:\n",
    "        xml_dir (str): Directory containing XML files\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with extracted information\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for xml_file in tqdm(report_paths):\n",
    "        try:\n",
    "\n",
    "            # Parse XML file\n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Initialize empty values\n",
    "            comparison = \"\"\n",
    "            indication = \"\"\n",
    "            findings = \"\"\n",
    "            impression = \"\"\n",
    "            \n",
    "            # Extract abstract text fields\n",
    "            abstract = root.find(\".//Abstract\")\n",
    "            if abstract is not None:\n",
    "                for abstract_text in abstract.findall(\"AbstractText\"):\n",
    "                    label = abstract_text.get(\"Label\")\n",
    "                    text_value = abstract_text.text\n",
    "                    \n",
    "                    # Check for \"None.\" and set to None\n",
    "                    if text_value == \"None.\":\n",
    "                        text_value = None\n",
    "                    \n",
    "                    if label == \"COMPARISON\":\n",
    "                        comparison = text_value\n",
    "                    elif label == \"INDICATION\": \n",
    "                        indication = text_value\n",
    "                    elif label == \"FINDINGS\":\n",
    "                        findings = text_value\n",
    "                    elif label == \"IMPRESSION\":\n",
    "                        impression = text_value\n",
    "            # Extract image information\n",
    "            for parent_image in root.findall(\".//parentImage\"):\n",
    "                image_id = parent_image.get(\"id\", \"\")\n",
    "                caption = parent_image.find(\"caption\")\n",
    "                caption_text = caption.text or None\n",
    "                image_path = os.path.join(NLMCXR_PNG_DIR, image_id+'.png')  \n",
    "                # Create a row for each image\n",
    "                data.append({\n",
    "                    'file_path': xml_file,\n",
    "                    'comparison': comparison,\n",
    "                    'indication': indication,\n",
    "                    'findings': findings,\n",
    "                    'impression': impression,\n",
    "                    'image_file_path': image_path, \n",
    "                    'image_caption': caption_text\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {xml_file}: {str(e)}\")\n",
    "            \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "nlmcxr_df = parse_xml_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlmcxr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlmcxr_df.info() \n",
    "nlmcxr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlmcxr_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of empty cells in each column\n",
    "null_cells_count = nlmcxr_df.isnull().sum()\n",
    "\n",
    "print(\"Number of null cells:\")\n",
    "print(null_cells_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_to_drop = (nlmcxr_df['comparison'].isnull() & nlmcxr_df['indication'].isnull() & nlmcxr_df['findings'].isnull() & nlmcxr_df['impression'].isnull())\n",
    "\n",
    "print(f\"Number of rows with all report fields empty: {mask_to_drop.sum()}\")\n",
    "\n",
    "print(\"Before removing samples: \", nlmcxr_df.shape)\n",
    "\n",
    "nlmcxr_df = nlmcxr_df[~mask_to_drop]\n",
    "nlmcxr_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"After removing samples: \", nlmcxr_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img_path: str, max_size: int=512) -> Image:\n",
    "    try:\n",
    "        img_copy = Image.open(img_path).copy()\n",
    "        img_copy.thumbnail((max_size, max_size))\n",
    "        return img_copy\n",
    "    except (UnidentifiedImageError, OSError) as e:\n",
    "        print(f\"Skipping corrupt image file: {img_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_save_images(row, target_size=512):\n",
    "\n",
    "    img_path = row['image_file_path']\n",
    "        \n",
    "    # Get the relative path of the image within the NLMCXR_PNG_DIR\n",
    "    relative_path = os.path.relpath(img_path, NLMCXR_PNG_DIR)\n",
    "    \n",
    "    # Create the resized image directory if it doesn't exist\n",
    "    resized_dir = os.path.join(NLMCXR_DIR, 'preprocessed', os.path.dirname(relative_path))\n",
    "    os.makedirs(resized_dir, exist_ok=True)\n",
    "    \n",
    "    # Get the resized image path\n",
    "    resized_image_path = os.path.join(resized_dir, f\"{os.path.splitext(os.path.basename(img_path))[0]}_resized.png\")\n",
    "    \n",
    "    #Add the resized image path to the dataframe\n",
    "    nlmcxr_df.loc[row.name, 'image_file_path_resized'] = resized_image_path\n",
    "    \n",
    "    # Resize and save image if it doesn't exist\n",
    "    if not os.path.exists(resized_image_path):\n",
    "        resized_image = resize_image(img_path, target_size)\n",
    "        if resized_image is not None:\n",
    "            resized_image.save(resized_image_path)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    return resized_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in tqdm(nlmcxr_df.iterrows(), total=len(nlmcxr_df)):\n",
    "    resize_and_save_images(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the Image_File_Path column if it exists\n",
    "if 'image_file_path' in nlmcxr_df.columns:\n",
    "    nlmcxr_df.drop(columns=['image_file_path'], inplace=True)\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Increase width to show full content of each cell\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Increase display width to show more horizontal content\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "#display first 40 rows in head\n",
    "nlmcxr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dir = STANZA_DIR + '/stanza_en'\n",
    "    # Initialize the Stanza pipeline\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize', model_dir = model_dir)\n",
    "\n",
    "def tokenize_sentences(text: str) -> list:\n",
    "    if not isinstance(text, str) or not text.strip():  # Check if text is a non-empty string\n",
    "        return []  # Return an empty list for invalid input\n",
    "\n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract sentences\n",
    "    tokenized_words = []\n",
    "    for sentence in doc.sentences:\n",
    "        tokenized_words.extend([word.text for word in sentence.words])\n",
    "    \n",
    "    return tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlmcxr_df['comparison_tokenized'] = nlmcxr_df['comparison'].apply(lambda x: tokenize_sentences(x))\n",
    "nlmcxr_df['indication_tokenized'] = nlmcxr_df['indication'].apply(lambda x: tokenize_sentences(x))\n",
    "nlmcxr_df['findings_tokenized'] = nlmcxr_df['findings'].apply(lambda x: tokenize_sentences(x))\n",
    "nlmcxr_df['impression_tokenized'] = nlmcxr_df['impression'].apply(lambda x: tokenize_sentences(x))\n",
    "nlmcxr_df['image_caption_tokenized'] = nlmcxr_df['image_caption'].apply(lambda x: tokenize_sentences(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlmcxr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if columns comparison, indication, findings, impression exist, drop them \n",
    "if 'comparison' in nlmcxr_df.columns:\n",
    "    nlmcxr_df.drop(columns=['comparison'], inplace=True)\n",
    "if 'indication' in nlmcxr_df.columns:\n",
    "    nlmcxr_df.drop(columns=['indication'], inplace=True)\n",
    "if 'findings' in nlmcxr_df.columns:\n",
    "    nlmcxr_df.drop(columns=['findings'], inplace=True)\n",
    "if 'impression' in nlmcxr_df.columns:\n",
    "    nlmcxr_df.drop(columns=['impression'], inplace=True)\n",
    "if 'image_caption' in nlmcxr_df.columns:\n",
    "    nlmcxr_df.drop(columns=['image_caption'], inplace=True)\n",
    "\n",
    "nlmcxr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(PROJECT_DIR, 'data/interims')\n",
    "\n",
    "file_path = os.path.join(directory, 'nlmcxr_preprocessed.pkl')\n",
    "\n",
    "print(\"Target Directory:\", directory)\n",
    "\n",
    "# Save the DataFrame\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(nlmcxr_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the file was saved correctly\n",
    "with open(file_path, 'rb') as f:\n",
    "    data_pkl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pkl.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convirt_fed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
