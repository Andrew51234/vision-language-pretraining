{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69caffdc",
   "metadata": {
    "heading_collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "## Imports\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=3)\n",
    "# import matplotlib.pyplot as plt\n",
    "# import stanza\n",
    "\n",
    "from stanza.server import CoreNLPClient\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdd424e",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc9c26",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Generating df experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2871faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_CXR_JPG = '/vol/aimspace/projects/physionet/mimic_cxr/mimic-cxr-jpg_2-0-0'\n",
    "MIMIC_CXR_REPORTS = '/vol/aimspace/projects/physionet/mimic_cxr/mimic-cxr_2-0-0' \n",
    "PROJECT_DIR = '/vol/aimspace/projects/practical_WS2425/vision_language'\n",
    "jpg_to_report_path = lambda x: x.replace('mimic-cxr-jpg_2-0-0', 'mimic-cxr_2-0-0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2605c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T07:42:46.902596Z",
     "start_time": "2022-12-03T07:42:46.712645Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ls $MIMIC_CXR_REPORTS/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6b1d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T07:42:51.314679Z",
     "start_time": "2022-12-03T07:42:48.470051Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "patient_folders = []\n",
    "# TODO change to 10-20\n",
    "# for i in range(10,20):\n",
    "#     patient_folders.extend(glob.glob(f'{MIMIC_CXR_DIR}/files/p{i}/p{i}*/'))\n",
    "patient_folders.extend(glob.glob(f'{MIMIC_CXR_REPORTS}/files/p10/p10*/'))\n",
    "print(len(patient_folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c1908e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_files = []\n",
    "for pf in tqdm(patient_folders):\n",
    "    image_files.extend(glob.glob(f'{pf}/s*/*.jpg'))\n",
    "print(len(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c1908e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_files = []\n",
    "for pf in tqdm(patient_folders):\n",
    "    image_files.extend(glob.glob(f'{pf}/s*/*.jpg'))\n",
    "print(len(image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800a9912",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_reports = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls {patient_folders[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eab575",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(f'{patient_folders[0]}/s56834987.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdafb7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:55:55.726960Z",
     "start_time": "2022-12-03T19:55:49.080601Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# study_ids_folders = glob.glob(f'{MIMIC_CXR_JPG}/files/p*/p*/s*/')\n",
    "study_ids_folders = glob.glob(f'{MIMIC_CXR_JPG}/files/p10/p10*/s*/')\n",
    "study_ids_folders[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f73ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:55:56.628303Z",
     "start_time": "2022-12-03T19:55:55.731233Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create dataframe with patient_folder, patient_id, study_id from paths\n",
    "text_reports_df = pd.DataFrame(np.vstack(pd.Series(study_ids_folders).parallel_apply(lambda x: x.split('/')[-4:-1]).values), columns=['patient_folder', 'patient_id', 'study_id'])\n",
    "text_reports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42a8c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:55:56.734057Z",
     "start_time": "2022-12-03T19:55:56.731443Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_reports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a8ea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:55:56.740871Z",
     "start_time": "2022-12-03T19:55:56.735318Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_findings_impressions(df, path):\n",
    "    findings, impression = '', ''\n",
    "    with open(f'{path}/files/{df[\"patient_folder\"]}/{df[\"patient_id\"]}/{df[\"study_id\"]}.txt') as f:\n",
    "        data = f.read()\n",
    "        # Check for both FINDINGS and impression\n",
    "        matches = re.search(r\"^([\\w\\W]+?)\\bFINDINGS\\b([\\w\\W]+?)\\bIMPRESSION\\b([\\w\\W]+?)$\", data)\n",
    "        if matches and len(matches.groups())==3:\n",
    "            findings = matches.group(2)\n",
    "            impression = matches.group(3)\n",
    "        if len(findings)==0:\n",
    "            findings_match = re.search(r\"^([\\w\\W]+?)\\bFINDINGS\\b([\\w\\W]+?)$\", data)\n",
    "            if findings_match and len(findings_match.groups())==2:\n",
    "                findings = findings_match.group(2)\n",
    "        if len(impression)==0:\n",
    "            impression_match = re.search(r\"^([\\w\\W]+?)\\bIMPRESSION\\b([\\w\\W]+?)$\", data)\n",
    "            #print(len(impression_match.groups()))\n",
    "            if impression_match and len(impression_match.groups())==2:\n",
    "                impression = impression_match.group(2)\n",
    "        \n",
    "    return findings, impression\n",
    "f, i = get_findings_impressions(text_reports_df.iloc[0], MIMIC_CXR_REPORTS)\n",
    "print(f)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandarallel.initialize(progress_bar=1)\n",
    "text_reports_df['finding'], text_reports_df['impression'] = zip(*text_reports_df.parallel_apply(lambda x: get_findings_impressions(x, MIMIC_CXR_REPORTS), axis=1))\n",
    "text_reports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandarallel.initialize(progress_bar=False)\n",
    "print('Removing reports with no findings nor impressions')\n",
    "mask_to_drop = text_reports_df.parallel_apply(lambda x: len(x['findings'])==0 and len(x['impression'])==0, axis=1)\n",
    "text_reports_df = text_reports_df[~mask_to_drop]\n",
    "print(f'Removed {mask_to_drop.sum()} reports with no findings nor impressions\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7942b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_findings_impressions(df):\n",
    "    # Vectorized operation to get both findings and impressions\n",
    "    results = df.parallel_apply(\n",
    "        lambda x: get_findings_impressions(x, MIMIC_CXR_REPORTS), \n",
    "        axis=1, \n",
    "        result_type='expand'\n",
    "    )\n",
    "    # Directly assign columns\n",
    "    df['findings'], df['impressions'] = results[0], results[1]\n",
    "    return df\n",
    "\n",
    "# Enable progress bar\n",
    "tqdm.pandas()\n",
    "# Process in single pass\n",
    "text_reports_df = process_findings_impressions(text_reports_df)\n",
    "text_reports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f0397",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:57:47.814347Z",
     "start_time": "2022-12-03T19:57:46.065926Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pandarallel.initialize(progress_bar=False)\n",
    "problem_df = text_reports_df[text_reports_df.parallel_apply(lambda x: not (x['findings']!='' or x['impressions']!=''), axis=1)]\n",
    "problem_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af922bc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T07:47:46.830683Z",
     "start_time": "2022-12-03T07:47:46.828242Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r = problem_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0dbb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T07:48:42.762270Z",
     "start_time": "2022-12-03T07:48:42.757295Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _, r in problem_df.sample(10).iterrows():\n",
    "    with open(f'{MIMIC_CXR_REPORTS}/files/{r[\"patient_folder\"]}/{r[\"patient_id\"]}/{r[\"study_id\"]}.txt') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    print(data)\n",
    "    \n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79985ac2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:57:49.578236Z",
     "start_time": "2022-12-03T19:57:47.816455Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove rows with empty findings and impressions\n",
    "print('Before removing samples:', text_reports_df.shape)\n",
    "has_empty_findings_or_impressions = text_reports_df.parallel_apply(lambda x: len(x['findings'])!=0 or len(x['impression'])!=0, axis=1)\n",
    "text_reports_df = text_reports_df[has_empty_findings_or_impressions]\n",
    "print('After removing samples:', text_reports_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a11f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "(~has_empty_findings_or_impressions).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafdbc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T19:57:51.621742Z",
     "start_time": "2022-12-03T19:57:49.805745Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_reports_df.apply(lambda x: len(x['findings'])==0 or len(x['impression'])==0, axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa20f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stanza\n",
    "# CORE_NLP_DIR = '/vol/aimspace/projects/practical_WS2425/vision_language/CORE_NLP'\n",
    "# stanza.install_corenlp(dir=CORE_NLP_DIR)\n",
    "# os.environ['CORENLP_HOME'] = CORE_NLP_DIR\n",
    "\n",
    "\n",
    "\n",
    "# No more CoreNLP server since pipeline is faster and easier to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza \n",
    "STANZA_DIR = f'{PROJECT_DIR}/stanza_resources'\n",
    "#stanza.download('en', model_dir=STANZA_DIR + '/stanza_en')\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize',\n",
    "                      model_dir=STANZA_DIR + '/stanza_en',\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1858fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the pipeline\n",
    "doc = nlp(text_reports_df.iloc[0]['findings'])\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    # merge sentences to get the original text\n",
    "    print(i)\n",
    "    print(' '.join([word.text for word in sentence.words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc.sentences[1].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9665a9e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T20:21:27.224950Z",
     "start_time": "2022-12-03T20:21:27.221287Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def get_sentences(tokenized_sentences):\n",
    "#     '''\n",
    "#     Old version, needs to be replaced since it does not work with the new stanza library, e.g. stanza.Pipeline\n",
    "#     '''\n",
    "#     final_sentences = []\n",
    "#     for sent in tokenized_sentences:\n",
    "#         if len(sent.token)>3:\n",
    "#             ## Convert tokens to a string and replace the intermediate new lines\n",
    "#             final_sent = ''.join(list(map(lambda x: x.before.replace('\\n', '')+x.word, list(sent.token)))).strip()\n",
    "#             if final_sent.startswith(\":\"):\n",
    "#                 final_sent = final_sent.replace(\":\", \"\").strip()\n",
    "#             final_sentences.append(final_sent)\n",
    "    \n",
    "#     return final_sentences\n",
    "\n",
    "def clean_text(sentence: stanza.models.common.doc.Sentence):\n",
    "    '''\n",
    "    Remove new lines and leading colons from the sentence\n",
    "    '''\n",
    "    final_sentence = sentence.text.replace('\\n', '').strip()\n",
    "    if final_sentence.startswith(\":\"):\n",
    "        final_sentence = final_sentence[1:].strip()\n",
    "\n",
    "    return final_sentence\n",
    "\n",
    "def get_sentences(document: stanza.Document):\n",
    "    '''\n",
    "    '''\n",
    "    final_sentences = []\n",
    "    for sentence in document.sentences:\n",
    "        if len(sentence.words)<3:\n",
    "            continue\n",
    "        final_sentences.append(clean_text(sentence))\n",
    "    return final_sentences\n",
    "\n",
    "get_sentences(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19921cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T20:31:03.189951Z",
     "start_time": "2022-12-03T20:31:03.183311Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_reports_df['findings_tokenized_sentences'] = None\n",
    "text_reports_df['impressions_tokenized_sentences'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b3f38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T20:31:19.185542Z",
     "start_time": "2022-12-03T20:31:19.181143Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1fa2f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T21:11:03.945160Z",
     "start_time": "2022-12-03T20:35:38.669668Z"
    },
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Old version with CoreNLPClient\n",
    "# with CoreNLPClient(properties={\n",
    "#       'annotators': 'tokenize'\n",
    "#   }, be_quiet=True) as client:\n",
    "#     for i, (idx, r) in tqdm(enumerate(text_reports_df.iterrows()), total=text_reports_df.shape[0]):\n",
    "#         cnlp_out = client.annotate(r['findings'])\n",
    "#         text_reports_df.loc[idx, 'findings_tokenized_sentences'] = get_sentences(cnlp_out.sentence)\n",
    "#         cnlp_out = client.annotate(r['impressions'])\n",
    "#         text_reports_df.loc[idx, 'impressions_tokenized_sentences'] = get_sentences(cnlp_out.sentence)\n",
    "#         if (i%100==0):\n",
    "#             print(i)\n",
    "\n",
    "# TODO is it faster to not use gpu for nlp but pandarallel\n",
    "# New version with stanza.Pipeline\n",
    "tqdm.pandas()\n",
    "# for findings:\n",
    "#text_reports_df['findings_tokenized_sentences'] = text_reports_df['findings'].progress_apply(lambda x: get_sentences(nlp(x)))\n",
    "# for impressions:\n",
    "text_reports_df['impressions_tokenized_sentences'] = text_reports_df['impression'].progress_apply(lambda x: get_sentences(nlp(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d59534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cleaning findings and impressions\n",
    "# def clean_text(text):\n",
    "#     # Replace newlines with spaces\n",
    "#     text = text.replace('\\n', ' ')\n",
    "#     # Remove leading colon if present\n",
    "#     return text[1:] if text.startswith(':') else text\n",
    "\n",
    "# # Apply the cleaning function to both columns\n",
    "# text_reports_df['findings'] = text_reports_df['findings'].apply(clean_text)\n",
    "# text_reports_df['impressions'] = text_reports_df['impressions'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f4241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T22:03:41.271121Z",
     "start_time": "2022-12-03T22:03:41.256683Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_reports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66856344",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_reports_df.iloc[2]['impressions_tokenized_sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103749eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls $PROJECT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33e8a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T22:11:19.847168Z",
     "start_time": "2022-12-03T22:11:18.738166Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the directory and file path\n",
    "# directory = 'data/processed/tokenized_reports'\n",
    "directory = f'{PROJECT_DIR}/data/interims'\n",
    "\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "file_path = os.path.join(directory, 'tokenized_text_reports.pkl')\n",
    "\n",
    "print(\"Target Directory:\", directory)\n",
    "\n",
    "# Save the DataFrame\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(text_reports_df, f)\n",
    "\n",
    "# # Verifying the file was saved correctly\n",
    "# with open(file_path, 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# # If it's a DataFrame, display the first few rows\n",
    "# if isinstance(data, pd.DataFrame):\n",
    "#     print(data.head())\n",
    "# else:\n",
    "#     # If it's not a DataFrame, just print the data\n",
    "#     print(data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "687545eb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Save this text_reports_df\n",
    "\n",
    "- Add another column with path to image files\n",
    "- Create a dataset class which will take data frame file name, client id and load the data frame in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62deef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate image file paths and check their existence\n",
    "def generate_image_path(row):\n",
    "    # Construct the directory path\n",
    "    directory_path = f'{MIMIC_CXR_JPG}/files/{row[\"patient_folder\"]}/{row[\"patient_id\"]}/{row[\"study_id\"]}'\n",
    "    \n",
    "    # Use glob to find all .jpg files in the directory\n",
    "    image_files = glob.glob(os.path.join(directory_path, '*.jpg'))\n",
    "    \n",
    "    # Print the directory and the files found\n",
    "    if not image_files:\n",
    "        print(\"No files found in directory: \" + directory_path)\n",
    "\n",
    "    return image_files\n",
    "\n",
    "# Add a new column with image file paths\n",
    "text_reports_df['image_files'] = text_reports_df.parallel_apply(generate_image_path, axis=1)\n",
    "text_reports_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddeb8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images are there per sample?\n",
    "text_reports_df['image_files'].apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image_path, target_size=(256, 256)):\n",
    "    # Load the image\n",
    "    original_image = Image.open(image_path)\n",
    "    \n",
    "    # Create a copy for resizing\n",
    "    resized_image = original_image.copy()\n",
    "    \n",
    "    # Resize the image to have a size of 256 on the larger side\n",
    "    resized_image.thumbnail(target_size)\n",
    "    \n",
    "    return original_image, resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f71e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(original, resized):\n",
    "    # Display the original and resized images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(resized)\n",
    "    axes[1].set_title('Resized Image')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb497fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the functions\n",
    "text_reports_df = data\n",
    "test_image_path = text_reports_df.iloc[0]['image_files'][0]\n",
    "print(test_image_path)\n",
    "\n",
    "original, resized = resize_image(test_image_path)\n",
    "print(original.size, resized.size)  \n",
    "\n",
    "# Display the images\n",
    "display_images(original, resized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6fccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=3)\n",
    "\n",
    "base_directory = f'{PROJECT_DIR}/data/processed/test'\n",
    "file_path = os.path.join(PROJECT_DIR, 'data/dataframes/report_images_resized_df.pkl')\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "     data = pickle.load(f)\n",
    "     \n",
    "data.drop('image_files_resized', axis=1, inplace=True)\n",
    "data.drop('impressions', axis=1, inplace=True)\n",
    "data.drop('findings', axis=1, inplace=True)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img_path:str, max_size: int=256) -> Image:\n",
    "    '''\n",
    "    Resize the image to have a size of max_size on the larger side\n",
    "    '''\n",
    "    img_copy = Image.open(img_path).copy()\n",
    "    img_copy.thumbnail((max_size, max_size))\n",
    "    return img_copy\n",
    "\n",
    "def resize_and_save_images(row, target_size=256):\n",
    "    resized_paths = []\n",
    "    save_dir = os.path.join(base_directory, row[\"patient_folder\"], row[\"patient_id\"], row[\"study_id\"])\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for path in row['image_files']:\n",
    "        # get resized image path\n",
    "        image_name = os.path.basename(path)\n",
    "        resized_image_path = os.path.join(save_dir, f'{os.path.splitext(image_name)[0]}_resized.jpg')\n",
    "        resized_paths.append(resized_image_path)\n",
    "        # resize and save image\n",
    "        if os.path.exists(resized_image_path):\n",
    "            continue\n",
    "        resized_image = resize_image(path, target_size)\n",
    "        resized_image.save(resized_image_path)\n",
    "\n",
    "    return resized_paths\n",
    "\n",
    "# Test resize function\n",
    "#tmp = resize_image(data.iloc[0]['image_files'][0])\n",
    "data['images_resized_names'] = data.parallel_apply(resize_and_save_images, axis=1)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd22c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = f'{PROJECT_DIR}/data/processed/report_images'\n",
    "\n",
    "text_reports_df['image_files_resized'] = [[] for _ in range(len(text_reports_df))]\n",
    "# Iterate over each row in the DataFrame\n",
    "for idx, row in tqdm(text_reports_df.iterrows(), total=text_reports_df.shape[0]):\n",
    "\n",
    "    resized_paths = []  # List to store resized image paths for the current row\n",
    "    # Iterate over each image path in the image_files column\n",
    "    for image_path in row['image_files']:        \n",
    "        # Extract the image name from the path\n",
    "        image_name = os.path.basename(image_path)\n",
    "        \n",
    "        # Construct the directory path for saving the resized image\n",
    "        save_directory = os.path.join(base_directory, row[\"patient_folder\"], row[\"patient_id\"], row[\"study_id\"])\n",
    "        \n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "        \n",
    "        # Save the resized image\n",
    "        resized_image_path = os.path.join(save_directory, f'{os.path.splitext(image_name)[0]}_resized.jpg')\n",
    "        if not os.path.exists(resized_image_path):\n",
    "            # Resize the image\n",
    "            original, resized = resize_image(image_path)\n",
    "            \n",
    "            # Save the resized image\n",
    "            resized.save(resized_image_path)        \n",
    "            \n",
    "        # Append the resized image path to the list\n",
    "        resized_paths.append(resized_image_path)\n",
    "    \n",
    "    # Assign the list of resized image paths to the new column\n",
    "    text_reports_df.at[idx, 'image_files_resized'] = resized_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af66980",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_reports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4178ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "directory = f'{PROJECT_DIR}/data/processed/report_images_resized'\n",
    "\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "file_path = os.path.join(directory, 'report_images_resized_df.pkl')\n",
    "\n",
    "print(\"Target Directory:\", directory)\n",
    "\n",
    "# Save the DataFrame\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(text_reports_df, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the dataframe\n",
    "def load_dataframe_from_pickle(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            return data\n",
    "        else:\n",
    "            print(\"The loaded data is not a DataFrame.\")\n",
    "            return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the file: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c94cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "file_path = f'{PROJECT_DIR}/data/dataframes/report_images_resized_df.pkl'\n",
    "# text_reports_df = load_dataframe_from_pickle(file_path) \n",
    "\n",
    "# text_reports_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIMICCXRDataset:\n",
    "    def __init__(self, df_file, client_id=None):\n",
    "        assert os.path.exists(df_file) and df_file.endswith('.pkl'), \"File must exist and be a .pkl file\"\n",
    "        \n",
    "        with open(df_file, 'rb') as f:\n",
    "            self.df = pickle.load(f)\n",
    "        \n",
    "        self.client_id = client_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            return self.df.iloc[idx]\n",
    "        elif isinstance(idx, slice):\n",
    "            return self.df.iloc[idx]\n",
    "        else:\n",
    "            raise TypeError(\"Index must be an integer or a slice\")\n",
    "\n",
    "# Example usage\n",
    "dataset = MIMICCXRDataset(file_path)\n",
    "\n",
    "# Access the first 10 records\n",
    "print(dataset[:10])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a08c924",
   "metadata": {
    "hidden": true,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "In the get_item fn:\n",
    " - Argument - Index to dataframe\n",
    " - Get the image fname and list of texts (findings & impressions)\n",
    " - Read the image and select a random text\n",
    " - Apply the image transformations\n",
    " - Return a dict - {'image': img, 'text': text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c7df4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T22:23:41.115518Z",
     "start_time": "2022-12-03T22:23:32.925758Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_reports_df.apply(lambda x: glob.glob(f'/MIMIC_CXR_JPG/files/{x[\"patient_folder\"]}/{x[\"patient_id\"]}/{x[\"study_id\"]}/*.jpg'), axis=1).apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95cad7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T22:30:10.675097Z",
     "start_time": "2022-12-03T22:30:02.687413Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_reports_df['image_files'] = text_reports_df.apply(lambda x: glob.glob(f'/MIMIC_CXR_JPG/files/{x[\"patient_folder\"]}/{x[\"patient_id\"]}/{x[\"study_id\"]}/*.jpg'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630056bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-03T23:06:15.656665Z",
     "start_time": "2022-12-03T23:06:15.264888Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_image_text_df = text_reports_df.explode(\"image_files\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50851c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T00:21:57.713310Z",
     "start_time": "2022-12-04T00:21:57.710258Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_image_text_df.rename(columns={'image_files':'image_fname'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c93fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T00:21:59.829375Z",
     "start_time": "2022-12-04T00:21:59.819362Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_image_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edabf73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T00:22:02.285280Z",
     "start_time": "2022-12-04T00:22:00.814823Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/scratch/tm3647/public/mimic_image_text_df.pkl', 'wb') as f:\n",
    "    pickle.dump(final_image_text_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c5662",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Reload Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb56efd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T22:40:02.287205Z",
     "start_time": "2022-12-07T22:40:01.071825Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/scratch/tm3647/public/mimic_image_text_df.pkl', 'rb') as f:\n",
    "    final_image_text_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771e8ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:07:40.114984Z",
     "start_time": "2022-12-07T23:07:40.104292Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_image_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1ff4c7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Resize images and store on the disk (later created squash out of this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9aadd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T18:33:11.989984Z",
     "start_time": "2022-12-07T18:30:59.367892Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_image_text_df['resized_image_fname'] = final_image_text_df['image_fname'].apply(lambda x: os.path.exists((os.path.splitext(x)[0]+'_resized.jpg').replace('/MIMIC_CXR_JPG/', '/vast/tm3647/physionet.org/files/mimic-cxr-jpg/2.0.0/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df685d82",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess(img, desired_size=320):\n",
    "    old_size = img.size\n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    # create a new image and paste the resized on it\n",
    "\n",
    "    new_img = Image.new('L', (desired_size, desired_size))\n",
    "    new_img.paste(img, ((desired_size-new_size[0])//2,\n",
    "                        (desired_size-new_size[1])//2))\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122c8a29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T18:23:11.861682Z",
     "start_time": "2022-12-07T18:23:11.858514Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def resize_and_save(record):\n",
    "    new_fname = os.path.splitext(record['image_fname'])[0]+'_resized.jpg'\n",
    "    new_fname = new_fname.replace('/MIMIC_CXR_JPG/', '/vast/tm3647/physionet.org/files/mimic-cxr-jpg/2.0.0/')\n",
    "    if os.path.exists(new_fname):\n",
    "        return\n",
    "    \n",
    "    image = pyvips.Image.new_from_file(record['image_fname'], access=\"sequential\")\n",
    "    mem_img = image.write_to_memory()\n",
    "    image = np.frombuffer(mem_img, dtype=np.uint8).reshape(image.height, image.width)\n",
    "    \n",
    "    img = preprocess(Image.fromarray(image))\n",
    "    img.save(new_fname)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12ea77d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T08:19:03.823613Z",
     "start_time": "2022-12-07T07:59:35.840445Z"
    },
    "hidden": true
   },
   "source": [
    "final_image_text_df.iloc[:10000].swifter.apply(lambda x: resize_and_save(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462c723e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T18:23:14.072529Z",
     "start_time": "2022-12-07T18:23:14.003995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b51454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T18:27:30.463631Z",
     "start_time": "2022-12-07T18:25:15.861714Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = Parallel(4, verbose=2)(delayed(resize_and_save)(r) for _,r in tqdm(final_image_text_df.iterrows(), total=final_image_text_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1272041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T08:25:06.487435Z",
     "start_time": "2022-12-07T08:25:06.483666Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_image_text_df.iloc[10000:11000].iloc[-1]['image_fname']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f24ea",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Add a resized images fname column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f516b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T22:43:37.555806Z",
     "start_time": "2022-12-07T22:43:37.552791Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_image_text_df.rename(columns={'image_fname':'orig_image_fname'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31424275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T22:45:50.629177Z",
     "start_time": "2022-12-07T22:45:50.211328Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_image_text_df['image_fname'] = final_image_text_df['orig_image_fname'].apply(lambda x: os.path.splitext(x)[0]+'_resized.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a601aa40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T22:45:55.028636Z",
     "start_time": "2022-12-07T22:45:53.881588Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_image_text_df['image_fname'].apply(lambda x: os.path.exists(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f6bc24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:07:51.243255Z",
     "start_time": "2022-12-07T23:07:51.198408Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Image.open(final_image_text_df['image_fname'].sample().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e173c1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Write the dataframe to the public folder (tejas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732fe342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T23:08:50.414759Z",
     "start_time": "2022-12-07T23:08:49.028984Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/scratch/tm3647/public/mimic_image_text_df.pkl', 'wb') as f:\n",
    "    pickle.dump(final_image_text_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c2d33",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f57db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T18:23:32.907500Z",
     "start_time": "2022-12-07T18:23:32.902011Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MIMICCXRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,  df_file:str , config=None, transforms=None, tokenizer=None):\n",
    "        super(MIMICCXRDataset, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        assert os.path.exists(df_file) and os.path.splitext(df_file)[1].lower()==\".pkl\", \"Check file path exists and has the extension .pkl\"\n",
    "        \n",
    "        with open(df_file, 'rb') as f:\n",
    "            self.df = pickle.load(f)\n",
    "        \n",
    "        self.transforms = transforms\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        record = self.df.iloc[idx]\n",
    "        \n",
    "        image = pyvips.Image.new_from_file(record['image_fname'], access=\"sequential\")\n",
    "        mem_img = image.write_to_memory()\n",
    "        image = np.frombuffer(mem_img, dtype=np.uint8).reshape(image.height, image.width)\n",
    "        #return image, record['image_fname']\n",
    "        \n",
    "        image = transforms.ToTensor()(cv2.cvtColor(image, cv2.COLOR_GRAY2RGB))\n",
    "        \n",
    "        findings = record['findings_tokenized_sentences']\n",
    "        impressions = record['impressions_tokenized_sentences']\n",
    "        \n",
    "        find_impres = findings + impressions\n",
    "        \n",
    "        assert len(find_impres)!=0, f\"Issue findings/impression of {record['patient_folder']}/{record['patient_id']}/{record['study_id']}\"\n",
    "        \n",
    "        text = np.random.choice(find_impres)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        if self.tokenizer:\n",
    "            tokenized_input_data = self.tokenizer(text, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        return {'image':image, 'text': text, 'tokenized_data':tokenized_input_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871bcd51",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96100909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T21:56:10.391244Z",
     "start_time": "2022-12-06T21:55:28.621955Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mds = MIMICDataset('/scratch/tm3647/public/mimic_image_text_df.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04624360",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T21:17:03.223110Z",
     "start_time": "2022-12-04T21:17:03.195429Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "source": [
    "read_image('/MIMIC_CXR_JPG/files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a77dfd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T21:17:07.463602Z",
     "start_time": "2022-12-04T21:17:06.466787Z"
    },
    "hidden": true
   },
   "source": [
    "plt.imshow(cv2.imread('/MIMIC_CXR_JPG/files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ac8c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T21:56:10.465453Z",
     "start_time": "2022-12-06T21:56:10.393076Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in mds:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061d977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T21:54:54.083902Z",
     "start_time": "2022-12-06T21:54:54.060979Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transforms.ToTensor()(i['image'].squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a9cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T21:57:56.248380Z",
     "start_time": "2022-12-06T21:57:56.245061Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f9546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T21:57:49.269359Z",
     "start_time": "2022-12-06T21:57:48.142832Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(transforms.ToPILImage()(i['image']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e372163",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Images write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac7016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T07:39:15.908913Z",
     "start_time": "2022-12-07T07:39:14.309048Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mds = MIMICCXRDataset('/scratch/tm3647/public/mimic_image_text_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa3c10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T07:52:41.841393Z",
     "start_time": "2022-12-07T07:52:08.336379Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for b in tqdm(mds):\n",
    "    img = preprocess(Image.fromarray(b[0]))\n",
    "    new_fname = os.path.splitext(b[1])[0]+'_resized.jpg'\n",
    "    new_fname = new_fname.replace('/MIMIC_CXR_JPG/', '/vast/tm3647/physionet.org/files/mimic-cxr-jpg/2.0.0/')\n",
    "    img.save(new_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc6c29",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pytorch DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96ee98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T04:34:19.987677Z",
     "start_time": "2022-12-07T04:34:19.982581Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac68d753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T04:34:54.507607Z",
     "start_time": "2022-12-07T04:34:54.505311Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc439b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T04:34:20.280053Z",
     "start_time": "2022-12-07T04:34:20.277525Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule \n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b887b619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T04:37:41.793168Z",
     "start_time": "2022-12-07T04:37:41.783438Z"
    },
    "code_folding": [
     3,
     24
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MIMICCXRDataModule(LightningDataModule):\n",
    "    \"\"\"Example of LightningDataModule for MNIST dataset.\n",
    "\n",
    "    A DataModule implements 5 key methods:\n",
    "\n",
    "        def prepare_data(self):\n",
    "            # things to do on 1 GPU/TPU (not on every GPU/TPU in DDP)\n",
    "            # download data, pre-process, split, save to disk, etc...\n",
    "        def setup(self, stage):\n",
    "            # things to do on every process in DDP\n",
    "            # load data, set variables, etc...\n",
    "        def train_dataloader(self):\n",
    "            # return train dataloader\n",
    "        def val_dataloader(self):\n",
    "            # return validation dataloader\n",
    "        def test_dataloader(self):\n",
    "            # return test dataloader\n",
    "        def teardown(self):\n",
    "            # called on every process in DDP\n",
    "            # clean up after fit or test\n",
    "\n",
    "    This allows you to share a full dataset without explaining how to download,\n",
    "    split, transform and process the data.\n",
    "\n",
    "    Read the docs:\n",
    "        https://pytorch-lightning.readthedocs.io/en/latest/data/datamodule.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mimic_cxr_dataset_file:str,\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = 0,\n",
    "        pin_memory: bool = False,\n",
    "        text_model_name:str = '',\n",
    "        #cfg: dict = {},\n",
    "    ):\n",
    "        super(MIMICCXRDataModule,).__init__()\n",
    "\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        # also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        ## Image transformations\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, ratio=[0.6, 1.0]),\n",
    "            transforms.RandomAffine(degrees=[-20,20], translate=(0.1,0.1), scale=(0.95, 1.05)),\n",
    "            transforms.ColorJitter(brightness=(0.6, 1.4), contrast=(0.6, 1.4)),\n",
    "            #transforms.GaussianBlur(G) ## Not implemented due to no info on kernel size in the paper\n",
    "            #transforms.ToTensor(),\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "        \n",
    "        ## Transforms\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(text_model_name, use_fast=True)\n",
    "\n",
    "        self.dataset: Optional[Dataset] = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Download data if needed.\n",
    "        Do not use it to assign state (self.x = y).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def setup(self):\n",
    "        \"\"\"Load data\n",
    "\n",
    "        This method is called by lightning with both `trainer.fit()` and `trainer.test()`, so be\n",
    "        careful not to execute things like random split twice!\n",
    "        \"\"\"\n",
    "        self.dataset = MIMICCXRDataset(self.hparams.mimic_cxr_dataset_file, transforms=self.transforms, tokenizer=self.tokenizer)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def teardown(self, stage: Optional[str] = None):\n",
    "        \"\"\"Clean up after fit or test.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"Extra things to save to checkpoint.\"\"\"\n",
    "        return {}\n",
    "\n",
    "    def load_state_dict(self, state_dict: Dict[str, Any]):\n",
    "        \"\"\"Things to do when loading checkpoint.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def collate_and_tokenize(self, batch):\n",
    "        input_data = {}\n",
    "        \n",
    "        images = torch.cat(list(map(lambda x: torch.unsqueeze(x['image'], 0), batch)))\n",
    "        texts = list(map(lambda x: x['text'], batch))\n",
    "        \n",
    "        input_data = self.tokenizer.batch_encode_plus(texts, max_length=128, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        keys = list(input_data.keys())\n",
    "        input_data['tokenized_text'] = {}\n",
    "        \n",
    "        for k in list(keys):\n",
    "            input_data['tokenized_text'][k]=input_data.pop(k)\n",
    "        \n",
    "        input_data['images'] = images\n",
    "        input_data['texts'] = texts\n",
    "        \n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13fad1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Exps"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a965982e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T19:53:49.335466Z",
     "start_time": "2022-12-06T19:53:49.331542Z"
    },
    "hidden": true
   },
   "source": [
    "dm.tokenizer('text', max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633eff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T04:39:35.006476Z",
     "start_time": "2022-12-07T04:39:34.675953Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dm = MIMICCXRDataModule('/scratch/tm3647/public/mimic_image_text_df.pkl', text_model_name='emilyalsentzer/Bio_ClinicalBERT', batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f2c1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-07T04:39:44.267106Z",
     "start_time": "2022-12-07T04:39:42.736386Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dm.setup()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58edfafe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T21:29:05.528498Z",
     "start_time": "2022-12-06T21:29:05.470965Z"
    },
    "hidden": true
   },
   "source": [
    "image = pyvips.Image.new_from_file('/MIMIC_CXR_JPG/files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg', access=\"sequential\")\n",
    "mem_img = image.write_to_memory()\n",
    "imgnp = np.frombuffer(mem_img, dtype=np.uint8).reshape(image.height, image.width)\n",
    "imgnp = cv2.cvtColor(imgnp, cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201e4de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T22:06:35.932094Z",
     "start_time": "2022-12-06T22:04:47.156040Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "st_time = time.time()\n",
    "for batch in tqdm(dm.train_dataloader()):\n",
    "    images, texts = batch['image'], batch['text']\n",
    "    print(time.time()-st_time)\n",
    "    st_time = time.time()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a66699",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Flow janky stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a49dfcc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "st_time = time.time()\n",
    "for batch in tqdm(dm.train_dataloader()):\n",
    "    images, texts = batch['image'], batch['text']\n",
    "    print(time.time()-st_time)\n",
    "    st_time = time.time()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007cbaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T19:48:46.604106Z",
     "start_time": "2022-12-06T19:48:46.600814Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch['tokenized_text']['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d535a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T19:46:09.926577Z",
     "start_time": "2022-12-06T19:46:09.923269Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d854b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T19:35:29.689480Z",
     "start_time": "2022-12-06T19:35:29.686240Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "images.shape, len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c505a77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T19:32:29.246161Z",
     "start_time": "2022-12-06T19:32:29.240809Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_model_input = dm.tokenizer(batch['texts'][:3], return_tensors=\"pt\", padding=True)\n",
    "text_model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ed4d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T19:32:41.447833Z",
     "start_time": "2022-12-06T19:32:39.520533Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_model = AutoModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7054bfb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T19:35:34.590595Z",
     "start_time": "2022-12-06T19:35:33.891684Z"
    },
    "hidden": true
   },
   "source": [
    "text_model_output = text_model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38826e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:38:50.434212Z",
     "start_time": "2022-12-05T03:38:50.125013Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_model_output = text_model(**text_model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd972bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:38:53.437296Z",
     "start_time": "2022-12-05T03:38:53.434963Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de06eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T02:45:29.449085Z",
     "start_time": "2022-12-05T02:45:29.012325Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_model = torchvision.models.resnet50()\n",
    "image_model = torch.nn.Sequential(*(list(image_model.children())[:-1]))\n",
    "torchsummary.summary(image_model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d441a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:39:13.078745Z",
     "start_time": "2022-12-05T03:39:12.937433Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_fv = image_model(batch['image'][0:3])\n",
    "image_fv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b7013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T02:57:42.485315Z",
     "start_time": "2022-12-05T02:57:42.481761Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94f2b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:39:25.337860Z",
     "start_time": "2022-12-05T03:39:25.301144Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentence_embeddings = mean_pooling(text_model_output, text_model_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7d628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:39:27.407329Z",
     "start_time": "2022-12-05T03:39:27.399441Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "proj_layer1 = torch.nn.Linear(768, 768)\n",
    "proj_layer2 = torch.nn.Linear(768, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93fe73d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:39:28.464582Z",
     "start_time": "2022-12-05T03:39:28.445497Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_proj_output = proj_layer2(proj_layer1(sentence_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b127e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:39:28.783181Z",
     "start_time": "2022-12-05T03:39:28.779985Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_proj_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e29445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:39:29.656148Z",
     "start_time": "2022-12-05T03:39:29.639550Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_proj_layer1 = torch.nn.Linear(2048, 1024)\n",
    "img_proj_layer2 = torch.nn.Linear(1024, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce203c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:39:40.053886Z",
     "start_time": "2022-12-05T03:39:40.029823Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_proj_output = img_proj_layer2(img_proj_layer1(image_fv.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ea307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:39:41.365174Z",
     "start_time": "2022-12-05T03:39:41.361872Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_proj_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee0728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:42:31.352335Z",
     "start_time": "2022-12-05T03:42:31.349791Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import cosine_similarity, pairwise_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627279d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:14:51.108266Z",
     "start_time": "2022-12-05T03:14:51.105790Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temperature = 0.1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09c14ea0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "u - 3x512\n",
    "v - 3x512\n",
    "\n",
    "u-v =  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04096b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:40:49.479008Z",
     "start_time": "2022-12-05T03:40:49.475204Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cosine_similarity(img_proj_output, text_proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e2dcd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:42:59.616760Z",
     "start_time": "2022-12-05T03:42:59.612766Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_proj_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba23184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:45:15.390877Z",
     "start_time": "2022-12-05T03:45:15.388248Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68ce6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:46:57.357273Z",
     "start_time": "2022-12-05T03:46:57.352927Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_text_sim = torchmetrics.functional.pairwise_cosine_similarity(img_proj_output, text_proj_output).detach()\n",
    "img_text_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baae182",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean[(-0.0250 / sum(-0.0250, -0.0479, -0.0319)), -0.0247 / sum(-0.0114, -0.0247, -0.0254), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36866733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:47:38.748947Z",
     "start_time": "2022-12-05T03:47:38.744275Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_img_sim = torchmetrics.functional.pairwise_cosine_similarity(text_proj_output, img_proj_output).detach()\n",
    "text_img_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e962ce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:56:23.096321Z",
     "start_time": "2022-12-05T03:56:23.092344Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = torch.exp(img_text_sim)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59484f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T04:10:57.286554Z",
     "start_time": "2022-12-05T04:10:57.282230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "-torch.log(0.9753 / sum(a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81121985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T04:14:03.779958Z",
     "start_time": "2022-12-05T04:14:03.775768Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.diag(-torch.nn.functional.log_softmax(img_text_sim, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9bd779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T04:15:12.231946Z",
     "start_time": "2022-12-05T04:15:12.229517Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lam = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee6f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T04:15:26.457051Z",
     "start_time": "2022-12-05T04:15:26.452232Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Final loss fn\n",
    "torch.mean(lam*torch.diag(-torch.nn.functional.log_softmax(img_text_sim, 1)) + (1-lam)*torch.diag(-torch.nn.functional.log_softmax(text_img_sim, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c1276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:31:15.970645Z",
     "start_time": "2022-12-05T03:31:15.966667Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vu_sim = cosine_similarity(img_proj_output, text_proj_output)\n",
    "vu_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b42c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T03:14:54.555816Z",
     "start_time": "2022-12-05T03:14:54.551884Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.exp(vu_sim/temperature) / torch.sum(torch.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a31aea",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c77a02d1",
   "metadata": {},
   "source": [
    "### ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1d5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389ad71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e8b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convirt_fed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
